{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6930e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Notebook evniroment configurations  ðŸ—\n",
    "\n",
    "#@markdown Is the repository mirrored from GitHub to DagsHub? \n",
    "MIRROR = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Clone the Git repo to the Colab runtime\n",
    "CLONE = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Pull the changes from the Git server to Colab runtime\n",
    "PULL_GIT = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Initialize DVC in this repository (Should only done once **per repository**)\n",
    "INIT_DVC = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Set DagsHub storage as DVC's remote (Should only done once per repository)\n",
    "SET_DVC_REMOTE = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Set DVCâ€™s user configurations for DagsHub user (will be set locally - should only done **per runtime**)\n",
    "SET_DVC_USER = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Pull the changes from the DagsHub storage to Colab runtime\n",
    "PULL_DVC = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Host DVC cache directory on Google Drive (will aviod pulling the data per runtime)\n",
    "GDRIVE_CACHE = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Configure MLflow remote tracking server\n",
    "MLFLOW = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Use Google Drive as the runtime memory disk (will change dirctory to the Drive)\n",
    "GDRIVE = False #@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aac019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title DagsHub Configurations ðŸ¶\n",
    "\n",
    "#@markdown Enter the DAGsHub repository owner name:\n",
    "DAGSHUB_REPO_OWNER= \"Nwoke\" #@param {type:\"string\"} \n",
    "\n",
    "#@markdown Enter the DAGsHub repository name:\n",
    "DAGSHUB_REPO_NAME= \"data_model_experiment-tracking\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the username of your DAGsHub account:\n",
    "DAGSHUB_USER_NAME = \"Nwoke\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the email for your DAGsHub account:\n",
    "DAGSHUB_EMAIL = \"tochukwunwoke1@gmail.com\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the branch name:\n",
    "BRANCH= \"main\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08f219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGSHUB_TOKEN = input('Please enter your dagshub token: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f996910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MIRROR:\n",
    "  # Set GitHub variables\n",
    "  GITHUB_REPO_OWNER = input(\"What is the repository owner username?\")\n",
    "  GITHUB_REPO_NAME = input(\"What is your GitHub repository name?\")\n",
    "  GITHUB_USER_NAME = input(\"What is your GitHub username?\")\n",
    "  GITHUB_EMAIL = input(\"What is the email for your GitHub account:\")\n",
    "  GITHUB_TOKEN = input('Please enter your GitHub token or password: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156ef8c9",
   "metadata": {},
   "source": [
    "**Configure Git**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe396ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MIRROR:\n",
    "  !git config --global user.email {GITHUB_EMAIL}\n",
    "  !git config --global user.name {GITHUB_USER_NAME}\n",
    "else:\n",
    "  !git config --global user.email {DAGSHUB_EMAIL}\n",
    "  !git config --global user.name {DAGSHUB_USER_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf29f5",
   "metadata": {},
   "source": [
    "**Clone the Repository**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ea1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLONE:\n",
    "  if MIRROR:\n",
    "    !git clone -b {BRANCH} https://{GITHUB_USER_NAME}:{GITHUB_TOKEN}@github.com/{GITHUB_REPO_OWNER}/{GITHUB_REPO_NAME}.git\n",
    "    %cd {GITHUB_REPO_NAME}\n",
    "  else:\n",
    "    !git clone -b {BRANCH} https://{DAGSHUB_USER_NAME}:{DAGSHUB_TOKEN}@dagshub.com/{DAGSHUB_REPO_OWNER}/{DAGSHUB_REPO_NAME}.git\n",
    "    %cd {DAGSHUB_REPO_NAME}\n",
    "if PULL_GIT:\n",
    "  !git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c5991",
   "metadata": {},
   "source": [
    "**Install Requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "!pip install --upgrade pip --quiet\n",
    "\n",
    "req_path = Path(\"requirements.txt\")\n",
    "if req_path.is_file():\n",
    "  !pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b55759",
   "metadata": {},
   "source": [
    "**Configure DVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7fbffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvc_installed = !pip list -v | grep dvc\n",
    "if not dvc_installed:\n",
    "  print(\"Installing DVC\")\n",
    "  !pip install dvc>=2.8.1 --quiet\n",
    "\n",
    "# Import DVC package (relevant only when working in a Colab environment)\n",
    "import dvc\n",
    "\n",
    "if INIT_DVC:\n",
    "  # initialize DVC\n",
    "  !dvc init\n",
    "\n",
    "if SET_DVC_REMOTE:\n",
    "  # Set DVC remote storage as 'DAGsHub storage'\n",
    "  !dvc remote add origin https://dagshub.com/{DAGSHUB_REPO_OWNER}/{DAGSHUB_REPO_NAME}.dvc\n",
    "\n",
    "if SET_DVC_USER:\n",
    "  # General DVC user configuration\n",
    "  !dvc remote modify --local origin auth basic\n",
    "  !dvc remote modify --local origin user {DAGSHUB_USER_NAME}\n",
    "  !dvc remote modify --local origin password {DAGSHUB_TOKEN}\n",
    "\n",
    "if PULL_DVC:\n",
    "  !dvc pull -r origin >& dev_null\n",
    "\n",
    "  # Make sure that all files were pulled\n",
    "  !dvc pull -r origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93238440",
   "metadata": {},
   "source": [
    "**Link cache directory to Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce68dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GDRIVE_CACHE:\n",
    "  # if not MOUNT_GDRIVE:\n",
    "  #   mount_gdrive()\n",
    "  \n",
    "  cache_path = input(\"Please enter the path where you want to store the cache. \"\n",
    "                    \"The path doesn't have to exist at the moment\")\n",
    "  \n",
    "  cache_path = add_prefix_colab_path(cache_path)\n",
    "  Path(cache_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "  output, error = link_gdrive_as_cache(cache_path)\n",
    "\n",
    "  if error:\n",
    "    print('WARNING:',error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a8ae7",
   "metadata": {},
   "source": [
    "**Configure MLflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b8b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MLFLOW:\n",
    "  \n",
    "  mlflow_installed = !pip list -v | grep mlflow\n",
    "  if not mlflow_installed:\n",
    "    print(\"Installing MLflow\")\n",
    "    !pip install mlflow --quiet\n",
    "\n",
    "  import mlflow\n",
    "  import os\n",
    "\n",
    "  os.environ['MLFLOW_TRACKING_USERNAME'] = DAGSHUB_USER_NAME\n",
    "  os.environ['MLFLOW_TRACKING_PASSWORD'] = DAGSHUB_TOKEN\n",
    "\n",
    "  mlflow.set_tracking_uri(f'https://dagshub.com/{DAGSHUB_REPO_OWNER}/{DAGSHUB_REPO_NAME}.mlflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470db1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b3a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import time\n",
    "print(mlflow.__version__)\n",
    "# import IPython.display as display\n",
    "\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec30b895",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec30b895",
    "outputId": "db6014ff-5597-4161-9ad8-bb07192fc463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.get_strategy()\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c9c9b",
   "metadata": {
    "id": "650c9c9b"
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c4f70f",
   "metadata": {
    "id": "96c4f70f"
   },
   "outputs": [],
   "source": [
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6852bc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6852bc8",
    "outputId": "9c8a59a5-65c5-4e7a-9884-5f7c0538dfd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFRecord Files: 69\n",
      "Validation TFRecord Files: 69\n",
      "Test TFRecord Files: 68\n"
     ]
    }
   ],
   "source": [
    "FILENAMES_PATH = \"data_store/data/American Sign Language Letters.v1-v1.tfrecord/\"\n",
    "\n",
    "TRAINING_FILENAMES =  FILENAMES_PATH + \"train/Letters.tfrecords\"\n",
    "VALID_FILENAMES = FILENAMES_PATH + \"valid/Letters.tfrecords\"\n",
    "TEST_FILENAMES = FILENAMES_PATH + \"test/Letters.tfrecords\"\n",
    "\n",
    "print(\"Train TFRecord Files:\", len(TRAINING_FILENAMES))\n",
    "print(\"Validation TFRecord Files:\", len(VALID_FILENAMES))\n",
    "print(\"Test TFRecord Files:\", len(TEST_FILENAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "732da708",
   "metadata": {
    "id": "732da708"
   },
   "outputs": [],
   "source": [
    "labeled = FILENAMES_PATH + \"/train/Letters_label_map.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae6f7622",
   "metadata": {
    "id": "ae6f7622"
   },
   "outputs": [],
   "source": [
    "# Create the dataset object for tfrecord file(s)\n",
    "\n",
    "def load_dataset(tf_filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(tf_filenames) \n",
    "    \n",
    "    dataset = dataset.with_options(ignore_order)  \n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c98b440a",
   "metadata": {
    "id": "c98b440a"
   },
   "outputs": [],
   "source": [
    "# Decoding function\n",
    "def parse_record(record):\n",
    "    tfrecord_feat_format = (\n",
    "                {\n",
    "                    \"image/encoded\": tf.io.FixedLenFeature([], tf.string),\n",
    "                    \"image/filename\": tf.io.FixedLenFeature([], tf.string),\n",
    "                    \"image/format\": tf.io.FixedLenFeature([], tf.string),\n",
    "                    \"image/height\": tf.io.FixedLenFeature([], tf.int64),\n",
    "                    \"image/object/bbox/xmax\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                    \"image/object/bbox/xmin\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                    \"image/object/bbox/ymax\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                    \"image/object/bbox/ymin\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                    \"image/object/class/label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "                    \"image/object/class/text\": tf.io.FixedLenFeature([], tf.string),\n",
    "                    \"image/width\": tf.io.FixedLenFeature([], tf.int64),\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    \n",
    "    \n",
    "    example = tf.io.parse_single_example(record, tfrecord_feat_format)\n",
    "\n",
    "\n",
    "\n",
    "    IMAGE_SIZE = [400, 400]\n",
    "\n",
    "    image =  tf.io.decode_jpeg(example[\"image/encoded\"], channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    xmax = tf.cast(example[\"image/object/bbox/xmax\"], tf.int32)\n",
    "    xmin = tf.cast(example[\"image/object/bbox/xmin\"], tf.int32)\n",
    "    ymax = tf.cast(example[\"image/object/bbox/ymax\"], tf.int32)\n",
    "    ymin = tf.cast(example[\"image/object/bbox/ymin\"], tf.int32)\n",
    "\n",
    "    box_width = xmax - xmin\n",
    "    box_height = ymax - ymin\n",
    "    image = tf.image.crop_to_bounding_box(image, ymin, xmin, box_height, box_width)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "\n",
    "  # more feature preprocessing\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # image = tfa.image.rotate(image, 40, interpolation='NEAREST')\n",
    "\n",
    "\n",
    "    # image = tf.cast(image, \"uint8\")\n",
    "    # image = tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "\n",
    "\n",
    "    label = example[\"image/object/class/label\"]\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    # label = tf.one_hot(label, depth=26)\n",
    "\n",
    "    \n",
    "    return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0824b3b4",
   "metadata": {
    "id": "0824b3b4"
   },
   "outputs": [],
   "source": [
    "def get_dataset(filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames) \n",
    "    \n",
    "    dataset = dataset.with_options(ignore_order) \n",
    "    \n",
    "    dataset = dataset.map(parse_record, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size=10 * BATCH_SIZE, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    # dataset = dataset.repeat()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e849ae8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e849ae8",
    "outputId": "039d4ce7-f77b-4c7e-ecfa-83cde8497641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None, 400, 400, 3), (None,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfr_dataset = get_dataset(TRAINING_FILENAMES)\n",
    "print(tfr_dataset)\n",
    "\n",
    "tfr_testdata = get_dataset(VALID_FILENAMES)\n",
    "print(tfr_testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1e175e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1e175e9",
    "outputId": "dbbb3bca-5e0f-4082-e52b-232c9afa438c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 12:17:48.099347: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n",
      "2022-04-17 12:17:48.224693: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n",
      "2022-04-17 12:17:48.283850: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 400, 400, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 200, 200, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280000)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 26)                33280026  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,280,922\n",
      "Trainable params: 33,280,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_cnn():\n",
    "    model = tf.keras.Sequential([\n",
    "      \n",
    "    tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu', input_shape=[400, 400, 3]),\n",
    "    # tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    # tf.keras.layers.Conv2D(kernel_size=3, filters=64, padding='same', activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    # tf.keras.layers.Conv2D(kernel_size=3, filters=128, padding='same', activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    # tf.keras.layers.Conv2D(kernel_size=3, filters=256, padding='same', activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(26,'softmax')\n",
    "    ])\n",
    "\n",
    "    # opt = SGD(learning_rate=learning_rate)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "                  )\n",
    "    # model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab22171",
   "metadata": {},
   "source": [
    "# Track training using Mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlflow.tracking.get_tracking_uri())\n",
    "print(mlflow.get_artifact_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001c065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "client.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ab736",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"Hand_Signs_x\"\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b85f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and set experiment by id\n",
    "if experiment.name != EXPERIMENT_NAME:\n",
    "    experiment_id = mlflow.create_experiment(\"Hand_Signs_2\", \n",
    "                                            artifact_location=\"/content/MLflow_TF-serving/data_store/artifacts/\")\n",
    "    print(experiment_id)\n",
    "    \n",
    "    # Set experiment by id\n",
    "    client.set_experiment_tag(experiment_id, \"CV.framework\", \"Tensorflow_CV\")\n",
    "    experiment = client.get_experiment(experiment_id)\n",
    "    print(\"Name: {}\".format(experiment.name))\n",
    "    print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "    print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "    print(\"Tags: {}\".format(experiment.tags))\n",
    "    print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ddcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment by name \n",
    "mlflow.set_experiment(experiment_name=\"Hand_Signs_x\")\n",
    "experiment = client.get_experiment_by_name(\"Hand_Signs\")\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a5ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.start_run(experiment_id=experiment.experiment_id, run_name=\"test_artifact store\")\n",
    "run = mlflow.active_run()\n",
    "print(\"run_id: {}; status: {}\".format(run.info.run_id, run.info.status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8787dd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8787dd8",
    "outputId": "38599a8f-f22c-4a1d-d299-0f264f387758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoke/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "2022-04-17 12:18:00.904245: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n",
      "2022-04-17 12:18:00.936728: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12/Unknown - 45s 3s/step - loss: 7360.5508 - sparse_categorical_accuracy: 0.0312"
     ]
    }
   ],
   "source": [
    "# Tracking\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "\n",
    "start_training = time.time()\n",
    "\n",
    "history = model.fit(tfr_dataset, \n",
    "          # steps_per_epoch=1513/BATCH_SIZE, \n",
    "          epochs=30, verbose=1)\n",
    "end_training = time.time()\n",
    "\n",
    "tf.keras.models.save_model(model, \"./model\")\n",
    "\n",
    "training_time = end_training - start_training\n",
    "\n",
    "mlflow.log_param(\"learning_rate\", 0.0001)\n",
    "mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "mlflow.log_metric('batchsize', BATCH_SIZE)\n",
    "mlflow.log_metric('training_accuracy', history.history['sparse_categorical_accuracy'][-1])\n",
    "mlflow.log_metric('training_loss', history.history['loss'][-1])\n",
    "\n",
    "mlflow.log_metric('training_time', training_time)\n",
    "# mlflow.log_artifact(\"./model\", artifact_path=./data_store/artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b852e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr_testdata = get_dataset(VALID_FILENAMES)\n",
    "steps_per_epoch = 145/BATCH_SIZE\n",
    "\n",
    "start_evaluating = time.time()\n",
    "val_loss, val_accuracy = model.evaluate(tfr_testdata,\n",
    "                                        # steps_per_epoch=steps_per_epoch\n",
    "                                        )\n",
    "\n",
    "end_evaluating = time.time()\n",
    "evaluating_time = end_evaluating - start_evaluating\n",
    "\n",
    "\n",
    "mlflow.log_metric('validation_accuracy', val_accuracy)\n",
    "mlflow.log_metric('validation_loss', val_loss)\n",
    "mlflow.log_metric('evaluating_time', evaluating_time)\n",
    "\n",
    "\n",
    "\n",
    "mlflow.end_run()\n",
    "run = mlflow.get_run(run.info.run_id)\n",
    "print(\"run_id: {}; status: {}\".format(run.info.run_id, run.info.status))\n",
    "print(\"--\")\n",
    "\n",
    "# Check for any active runs\n",
    "print(\"Active run: {}\".format(mlflow.active_run()))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "American_Hand_Sign .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bad0a203fad3bf4bbc9662a4ce308684208b40e5a6cfafb23db855090affa21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
