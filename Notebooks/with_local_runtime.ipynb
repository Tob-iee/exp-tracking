{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import time\n",
    "import getpass\n",
    "print(mlflow.__version__)\n",
    "# import IPython.display as display\n",
    "\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'Nwoke'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = getpass.getpass('Please enter your DAGsHub token or password: ')\n",
    "os.environ['MLFLOW_TRACKING_PROJECTNAME'] = 'Mlflow-Dagshub_Exp-Tracking'\n",
    "os.environ['MLFLOW_TRACKING_URI'] = \"https://dagshub.com/Nwoke/Mlflow-Dagshub_Exp-Tracking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec30b895",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec30b895",
    "outputId": "db6014ff-5597-4161-9ad8-bb07192fc463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.get_strategy()\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c9c9b",
   "metadata": {
    "id": "650c9c9b"
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c4f70f",
   "metadata": {
    "id": "96c4f70f"
   },
   "outputs": [],
   "source": [
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6852bc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6852bc8",
    "outputId": "9c8a59a5-65c5-4e7a-9884-5f7c0538dfd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFRecord Files: 69\n",
      "Validation TFRecord Files: 69\n",
      "Test TFRecord Files: 68\n"
     ]
    }
   ],
   "source": [
    "FILENAMES_PATH = \"data_store/data/American Sign Language Letters.v1-v1.tfrecord/\"\n",
    "\n",
    "TRAINING_FILENAMES =  FILENAMES_PATH + \"train/Letters.tfrecords\"\n",
    "VALID_FILENAMES = FILENAMES_PATH + \"valid/Letters.tfrecords\"\n",
    "TEST_FILENAMES = FILENAMES_PATH + \"test/Letters.tfrecords\"\n",
    "\n",
    "print(\"Train TFRecord Files:\", len(TRAINING_FILENAMES))\n",
    "print(\"Validation TFRecord Files:\", len(VALID_FILENAMES))\n",
    "print(\"Test TFRecord Files:\", len(TEST_FILENAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "732da708",
   "metadata": {
    "id": "732da708"
   },
   "outputs": [],
   "source": [
    "labeled = FILENAMES_PATH + \"/train/Letters_label_map.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae6f7622",
   "metadata": {
    "id": "ae6f7622"
   },
   "outputs": [],
   "source": [
    "# Create the dataset object for tfrecord file(s)\n",
    "\n",
    "def load_dataset(tf_filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(tf_filenames) \n",
    "    \n",
    "    dataset = dataset.with_options(ignore_order)  \n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c98b440a",
   "metadata": {
    "id": "c98b440a"
   },
   "outputs": [],
   "source": [
    "# Decoding function\n",
    "def parse_record(record):\n",
    "    tfrecord_feat_format = (\n",
    "                {\n",
    "                    \"image/encoded\": tf.io.FixedLenFeature([], tf.string),\n",
    "                    \"image/filename\": tf.io.FixedLenFeature([], tf.string),\n",
    "                    \"image/format\": tf.io.FixedLenFeature([], tf.string),\n",
    "                    \"image/height\": tf.io.FixedLenFeature([], tf.int64),\n",
    "                    \"image/object/bbox/xmax\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                    \"image/object/bbox/xmin\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                    \"image/object/bbox/ymax\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                    \"image/object/bbox/ymin\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                    \"image/object/class/label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "                    \"image/object/class/text\": tf.io.FixedLenFeature([], tf.string),\n",
    "                    \"image/width\": tf.io.FixedLenFeature([], tf.int64),\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    \n",
    "    \n",
    "    example = tf.io.parse_single_example(record, tfrecord_feat_format)\n",
    "\n",
    "\n",
    "\n",
    "    IMAGE_SIZE = [400, 400]\n",
    "\n",
    "    image =  tf.io.decode_jpeg(example[\"image/encoded\"], channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    xmax = tf.cast(example[\"image/object/bbox/xmax\"], tf.int32)\n",
    "    xmin = tf.cast(example[\"image/object/bbox/xmin\"], tf.int32)\n",
    "    ymax = tf.cast(example[\"image/object/bbox/ymax\"], tf.int32)\n",
    "    ymin = tf.cast(example[\"image/object/bbox/ymin\"], tf.int32)\n",
    "\n",
    "    box_width = xmax - xmin\n",
    "    box_height = ymax - ymin\n",
    "    image = tf.image.crop_to_bounding_box(image, ymin, xmin, box_height, box_width)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "\n",
    "  # more feature preprocessing\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # image = tfa.image.rotate(image, 40, interpolation='NEAREST')\n",
    "\n",
    "\n",
    "    # image = tf.cast(image, \"uint8\")\n",
    "    # image = tf.image.encode_jpeg(image, format='rgb', quality=100)\n",
    "\n",
    "\n",
    "    label = example[\"image/object/class/label\"]\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    # label = tf.one_hot(label, depth=26)\n",
    "\n",
    "    \n",
    "    return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0824b3b4",
   "metadata": {
    "id": "0824b3b4"
   },
   "outputs": [],
   "source": [
    "def get_dataset(filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames) \n",
    "    \n",
    "    dataset = dataset.with_options(ignore_order) \n",
    "    \n",
    "    dataset = dataset.map(parse_record, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size=10 * BATCH_SIZE, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    # dataset = dataset.repeat()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e849ae8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e849ae8",
    "outputId": "039d4ce7-f77b-4c7e-ecfa-83cde8497641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None, 400, 400, 3), (None,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfr_dataset = get_dataset(TRAINING_FILENAMES)\n",
    "print(tfr_dataset)\n",
    "\n",
    "tfr_testdata = get_dataset(VALID_FILENAMES)\n",
    "print(tfr_testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1e175e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1e175e9",
    "outputId": "dbbb3bca-5e0f-4082-e52b-232c9afa438c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 12:17:48.099347: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n",
      "2022-04-17 12:17:48.224693: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n",
      "2022-04-17 12:17:48.283850: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 400, 400, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 200, 200, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280000)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 26)                33280026  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,280,922\n",
      "Trainable params: 33,280,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_cnn():\n",
    "    model = tf.keras.Sequential([\n",
    "      \n",
    "    tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu', input_shape=[400, 400, 3]),\n",
    "    # tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    # tf.keras.layers.Conv2D(kernel_size=3, filters=64, padding='same', activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    # tf.keras.layers.Conv2D(kernel_size=3, filters=128, padding='same', activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    # tf.keras.layers.Conv2D(kernel_size=3, filters=256, padding='same', activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(26,'softmax')\n",
    "    ])\n",
    "\n",
    "    # opt = SGD(learning_rate=learning_rate)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "                  )\n",
    "    # model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab22171",
   "metadata": {},
   "source": [
    "# Track training using Mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d533f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = f'https://dagshub.com/' + os.environ['MLFLOW_TRACKING_USERNAME'] + '/' + os.environ['MLFLOW_TRACKING_PROJECTNAME'] + '.mlflow'\n",
    "mlflow.set_tracking_uri(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlflow.tracking.get_tracking_uri())\n",
    "print(mlflow.get_artifact_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001c065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "client.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ab736",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"Hand_Signs_x\"\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b85f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and set experiment by id\n",
    "if experiment.name != EXPERIMENT_NAME:\n",
    "    experiment_id = mlflow.create_experiment(\"Hand_Signs_2\", \n",
    "                                            artifact_location=\"/content/MLflow_TF-serving/data_store/artifacts/\")\n",
    "    print(experiment_id)\n",
    "    \n",
    "    # Set experiment by id\n",
    "    client.set_experiment_tag(experiment_id, \"CV.framework\", \"Tensorflow_CV\")\n",
    "    experiment = client.get_experiment(experiment_id)\n",
    "    print(\"Name: {}\".format(experiment.name))\n",
    "    print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "    print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "    print(\"Tags: {}\".format(experiment.tags))\n",
    "    print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ddcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment by name \n",
    "mlflow.set_experiment(experiment_name=\"Hand_Signs_x\")\n",
    "experiment = client.get_experiment_by_name(\"Hand_Signs\")\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a5ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.start_run(experiment_id=experiment.experiment_id, run_name=\"test_artifact store\")\n",
    "run = mlflow.active_run()\n",
    "print(\"run_id: {}; status: {}\".format(run.info.run_id, run.info.status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8787dd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8787dd8",
    "outputId": "38599a8f-f22c-4a1d-d299-0f264f387758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwoke/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "2022-04-17 12:18:00.904245: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n",
      "2022-04-17 12:18:00.936728: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 133120000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12/Unknown - 45s 3s/step - loss: 7360.5508 - sparse_categorical_accuracy: 0.0312"
     ]
    }
   ],
   "source": [
    "# Tracking\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "\n",
    "start_training = time.time()\n",
    "\n",
    "history = model.fit(tfr_dataset, \n",
    "          # steps_per_epoch=1513/BATCH_SIZE, \n",
    "          epochs=30, verbose=1)\n",
    "end_training = time.time()\n",
    "\n",
    "tf.keras.models.save_model(model, \"./model\")\n",
    "\n",
    "training_time = end_training - start_training\n",
    "\n",
    "mlflow.log_param(\"learning_rate\", 0.0001)\n",
    "mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "mlflow.log_metric('batchsize', BATCH_SIZE)\n",
    "mlflow.log_metric('training_accuracy', history.history['sparse_categorical_accuracy'][-1])\n",
    "mlflow.log_metric('training_loss', history.history['loss'][-1])\n",
    "\n",
    "mlflow.log_metric('training_time', training_time)\n",
    "# mlflow.log_artifact(\"./model\", artifact_path=./data_store/artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b852e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr_testdata = get_dataset(VALID_FILENAMES)\n",
    "steps_per_epoch = 145/BATCH_SIZE\n",
    "\n",
    "start_evaluating = time.time()\n",
    "val_loss, val_accuracy = model.evaluate(tfr_testdata,\n",
    "                                        # steps_per_epoch=steps_per_epoch\n",
    "                                        )\n",
    "\n",
    "end_evaluating = time.time()\n",
    "evaluating_time = end_evaluating - start_evaluating\n",
    "\n",
    "\n",
    "mlflow.log_metric('validation_accuracy', val_accuracy)\n",
    "mlflow.log_metric('validation_loss', val_loss)\n",
    "mlflow.log_metric('evaluating_time', evaluating_time)\n",
    "\n",
    "\n",
    "\n",
    "mlflow.end_run()\n",
    "run = mlflow.get_run(run.info.run_id)\n",
    "print(\"run_id: {}; status: {}\".format(run.info.run_id, run.info.status))\n",
    "print(\"--\")\n",
    "\n",
    "# Check for any active runs\n",
    "print(\"Active run: {}\".format(mlflow.active_run()))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "American_Hand_Sign .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
